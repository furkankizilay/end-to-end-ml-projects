{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.datasets import imdb\n",
    "from keras_preprocessing.sequence import pad_sequences # cümlelerin uzunluklarını fixlemek için kullanılır\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding # intgerları yoğunluk vektörlerine çevirmek için kullanılır\n",
    "from keras.layers import SimpleRNN, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "max_len = 130\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Type:  <class 'numpy.ndarray'>\n",
      "Y_train Type:  <class 'numpy.ndarray'>\n",
      "X_train shape: (25000,)\n",
      "Y_train shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Type: \", type(x_train))\n",
    "print(\"Y_train Type: \", type(y_train))\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"Y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = 40000\n",
    "num_testing_samples = 10000\n",
    "\n",
    "# Combine the training and testing data to split them again\n",
    "x_combined = np.concatenate((x_train, x_test), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Shuffle the combined data to ensure random distribution\n",
    "indices = np.arange(len(x_combined))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Select the first num_training_samples for training and the next num_testing_samples for testing\n",
    "x_train = x_combined[indices[:num_training_samples]]\n",
    "y_train = y_combined[indices[:num_training_samples]]\n",
    "x_test = x_combined[indices[num_training_samples:num_training_samples + num_testing_samples]]\n",
    "y_test = y_combined[indices[num_training_samples:num_training_samples + num_testing_samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Type:  <class 'numpy.ndarray'>\n",
      "Y_train Type:  <class 'numpy.ndarray'>\n",
      "X_train shape: (40000,)\n",
      "Y_train shape:  (40000,)\n",
      "X_test Type:  <class 'numpy.ndarray'>\n",
      "Y_test Type:  <class 'numpy.ndarray'>\n",
      "X_test shape: (10000,)\n",
      "Y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Type: \", type(x_train))\n",
    "print(\"Y_train Type: \", type(y_train))\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"Y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_test Type: \", type(x_test))\n",
    "print(\"Y_test Type: \", type(y_test))\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"Y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2203     2     7 ...  4254  1080 16425]\n",
      " [    4   136   121 ...  2286    19    72]\n",
      " [  442    56    18 ...    20     9  3545]\n",
      " ...\n",
      " [  260    24   110 ...  1821     4   167]\n",
      " [ 4391    16    87 ...   107  3366    56]\n",
      " [    0     0     0 ...  2266  5123   382]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 130, 32)           640000    \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646,273\n",
      "Trainable params: 646,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rnn = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "embedding_dim = 32\n",
    "rnn.add(Embedding(num_words, embedding_dim, input_length=max_len))\n",
    "\n",
    "# SimpleRNN layer with 64 nodes and relu activation\n",
    "rnn.add(SimpleRNN(64, input_shape=(num_words, max_len), activation=\"relu\"))\n",
    "\n",
    "# Dense output layer\n",
    "rnn.add(Dense(1))\n",
    "rnn.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# Print the summary of the model\n",
    "print(rnn.summary())\n",
    "\n",
    "# Compile the model\n",
    "rnn.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 10s 29ms/step - loss: 0.6361 - accuracy: 0.6956 - val_loss: 0.3830 - val_accuracy: 0.8524\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.3881 - accuracy: 0.8521 - val_loss: 0.3566 - val_accuracy: 0.8503\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.3013 - accuracy: 0.8801 - val_loss: 0.3240 - val_accuracy: 0.8651\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.2571 - accuracy: 0.8999 - val_loss: 0.2998 - val_accuracy: 0.8741\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2306 - accuracy: 0.9117 - val_loss: 0.3130 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(np.array(x_train), np.array(y_train), validation_data=(np.array(x_test), np.array(y_test)), epochs=5, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify the sentiment of a sentence\n",
    "def classify_sentiment(sentence):\n",
    "    # Preprocess the input sentence and convert it to a sequence\n",
    "    word_to_index = imdb.get_word_index()\n",
    "    sentence = sentence.lower().split()\n",
    "    sequence = []\n",
    "    for word in sentence:\n",
    "        index = word_to_index.get(word, 0)  # Use index 0 for unknown words\n",
    "        if index < num_words:\n",
    "            sequence.append(index + 3)  # Add 3 to the index to account for reserved indices (0, 1, 2)\n",
    "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "    \n",
    "    # Predict the sentiment using the trained model\n",
    "    prediction = rnn.predict(sequence)[0][0]\n",
    "    \n",
    "    # Return the result\n",
    "    if prediction >= 0.5:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "Sentence: 'I love you Aleyna <4-1' \n",
      "Sentiment: Positive\n",
      "   ******       ******   \n",
      " **    ***     ***    ** \n",
      "**       **   **       **\n",
      "**        ** **        **\n",
      "**         ***         **\n",
      " **                   ** \n",
      "   **               **   \n",
      "     **           **     \n",
      "       **       **       \n",
      "         **   **         \n",
      "           ***           \n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"I love you Aleyna <4-1\"\n",
    "result = classify_sentiment(input_sentence)\n",
    "print(f\"Sentence: '{input_sentence}' \\nSentiment: {result}\")\n",
    "if result == \"Positive\":\n",
    "    draw_heart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heart():\n",
    "    heart = [\n",
    "        \"   ******       ******   \",\n",
    "        \" **    ***     ***    ** \",\n",
    "        \"**       **   **       **\",\n",
    "        \"**        ** **        **\",\n",
    "        \"**         ***         **\",\n",
    "        \" **                   ** \",\n",
    "        \"   **               **   \",\n",
    "        \"     **           **     \",\n",
    "        \"       **       **       \",\n",
    "        \"         **   **         \",\n",
    "        \"           ***           \"\n",
    "    ]\n",
    "\n",
    "    for line in heart:\n",
    "        print(line)\n",
    "        time.sleep(0.5)  # Her satırı ekranda 0.5 saniye beklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ******       ******   \n",
      " **    ***     ***    ** \n",
      "**       **   **       **\n",
      "**        ** **        **\n",
      "**         ***         **\n",
      " **                   ** \n",
      "   **               **   \n",
      "     **           **     \n",
      "       **       **       \n",
      "         **   **         \n",
      "           ***           \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "draw_heart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
